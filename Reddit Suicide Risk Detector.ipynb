{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae0ef9a",
   "metadata": {},
   "source": [
    "# Reddit Suicide Risk Detector: End-to-End Documentation\n",
    "\n",
    "## 1. Project Overview\n",
    "\n",
    "This project builds a system that tries to automatically detect whether a Reddit post is likely to be about suicide risk or not. The steps in the notebook are designed to take you from raw data (posts from Reddit) to a working tool that can make predictions on new posts.\n",
    "\n",
    "## 2. Environment Setup\n",
    "\n",
    "Install dependencies:\n",
    "\n",
    "```bash\n",
    "pip install pandas scikit-learn nltk praw flask joblib\n",
    "```\n",
    "\n",
    "Download NLTK resources:\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "```\n",
    "\n",
    "\n",
    "## 3. Data Collection\n",
    "\n",
    "Gather posts from Reddit using a tool (PRAW) that connects to Reddit’s servers. This serves as real data of how people write about their feelings or emotions.\n",
    "\n",
    "```python\n",
    "import praw\n",
    "import pandas as pd\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"YOUR_CLIENT_ID\",\n",
    "    client_secret=\"YOUR_CLIENT_SECRET\",\n",
    "    user_agent=\"YOUR_USER_AGENT\"\n",
    ")\n",
    "\n",
    "subreddits = [\"SuicideWatch\", \"depression\", \"anxiety\", \"mentalhealth\", \"mentalillness\", \"BPD\", \"bipolar\",\n",
    "        \"autism\", \"MentalHealthUK\", \"socialanxiety\", \"talktherapy\", \"askatherapist\", \"offmychest\",\n",
    "        \"traumatoolbox\", \"dbtselfhelp\", \"bodyacceptance\", \"MMFB\", \"mentalhealthmemes\", \"anxietymemes\",\n",
    "        \"MentalHealthSupport\", \"malementalhealth\", \"mentalhealthph\", \"mentalhealthsupport\",\n",
    "        \"mentalhealthbabies\", \"emotionalsupport\", \"helpme\", \"Advice\", \"KindVoice\", \"Vent\", \"venting\",\n",
    "        \"Feels\", \"sad\", \"CasualConversation\", \"MomForAMinute\", \"DadForAMinute\", \"BenignExistence\",\n",
    "        \"findafriend\", \"relationship_advice\", \"internetparents\", \"freecompliments\", \"Confessions\",\n",
    "        \"Offmychest\", \"AskReddit\", \"TodayILearned\", \"pics\", \"funny\", \"worldnews\", \"science\", \"movies\",\n",
    "        \"books\", \"technology\", \"gaming\", \"sports\", \"Music\", \"Art\", \"food\", \"DIY\", \"space\", \"History\",\n",
    "        \"television\", \"Documentaries\", \"InternetIsBeautiful\", \"travel\", \"photography\", \"cooking\",\n",
    "        \"gardening\", \"Fitness\", \"cars\", \"Bicycling\", \"boardgames\", \"CampingandHiking\", \"coffee\", \"tea\",\n",
    "        \"knitting\", \"woodworking\"]\n",
    "\n",
    "posts = []\n",
    "for subreddit_name in subreddits:\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    for submission in subreddit.new(limit=limit):\n",
    "        posts.append({\n",
    "            \"post_id\": submission.id,\n",
    "            \"subreddit\": subreddit_name,\n",
    "            \"title\": submission.title,\n",
    "            \"post_text\": submission.selftext\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(posts)\n",
    "df.to_csv(\"reddit_posts.csv\", index=False)\n",
    "```\n",
    "\n",
    "\n",
    "## 4. Data Cleaning\n",
    "\n",
    "Remove repeated posts, empty posts, or posts missing important parts. Clean data ensures the model learns patterns that are real and not just noise.\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"reddit_posts.csv\")\n",
    "df = df.drop_duplicates(subset=[\"post_id\"])\n",
    "df = df.dropna(subset=[\"title\", \"post_text\"])\n",
    "df = df[(df[\"title\"].str.strip() != \"\") | (df[\"post_text\"].str.strip() != \"\")]\n",
    "df.to_csv(\"reddit_posts_cleaned.csv\", index=False)\n",
    "```\n",
    "\n",
    "\n",
    "## 5. Data Labeling\n",
    "\n",
    "Assign a label to each post: “high-risk” (from mental health subreddits) or “neutral” (from general subreddits).\n",
    "\n",
    "```python\n",
    "mental_health_subs = [\n",
    "    \"SuicideWatch\", \"depression\", \"anxiety\", \"mentalhealth\", \"mentalillness\",\n",
    "    \"BPD\", \"bipolar\", \"autism\", \"MentalHealthUK\", \"socialanxiety\", \"talktherapy\",\n",
    "    \"askatherapist\", \"offmychest\", \"traumatoolbox\", \"dbtselfhelp\", \"bodyacceptance\",\n",
    "    \"MMFB\", \"mentalhealthmemes\", \"anxietymemes\", \"MentalHealthSupport\",\n",
    "    \"malementalhealth\", \"mentalhealthph\", \"mentalhealthsupport\", \"mentalhealthbabies\",\n",
    "    \"emotionalsupport\", \"helpme\", \"Advice\", \"KindVoice\", \"Vent\", \"venting\", \"Feels\",\n",
    "    \"sad\", \"CasualConversation\", \"MomForAMinute\", \"DadForAMinute\", \"BenignExistence\",\n",
    "    \"findafriend\", \"relationship_advice\", \"internetparents\", \"freecompliments\",\n",
    "    \"Confessions\", \"Offmychest\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\"reddit_posts_cleaned.csv\")\n",
    "df[\"label\"] = df[\"subreddit\"].apply(lambda x: 1 if x in mental_health_subs else 0)\n",
    "df.to_csv(\"reddit_posts_labeled.csv\", index=False)\n",
    "```\n",
    "\n",
    "\n",
    "## 6. Text Preprocessing\n",
    "\n",
    "Lowercase the text, remove punctuation, remove common words (like “the”, “and”), and reduce words to their root form (e.g., “helping” becomes “help”). Preprocessing makes the text easier for the model to analyze and reduces meaningless differences.\n",
    "\n",
    "```python\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df = pd.read_csv(\"reddit_posts_labeled.csv\")\n",
    "df[\"clean_text\"] = df[\"title\"].fillna(\"\") + \" \" + df[\"post_text\"].fillna(\"\")\n",
    "df[\"clean_text\"] = df[\"clean_text\"].apply(clean_text)\n",
    "df.to_csv(\"reddit_posts_preprocessed.csv\", index=False)\n",
    "```\n",
    "\n",
    "\n",
    "## 7. Feature Extraction\n",
    "\n",
    "Convert words in each post into numbers that represent how important each word is in that post, compared to all other posts. TF-IDF turns text into a format (numbers) the model can use.\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = pd.read_csv(\"reddit_posts_preprocessed.csv\")\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df[\"clean_text\"])\n",
    "y = df[\"label\"]\n",
    "```\n",
    "\n",
    "\n",
    "## 8. Model Training\n",
    "\n",
    "Teach a mathematical model to distinguish between high-risk and neutral posts using the numbers generated above. The model needs to learn the difference between risky and neutral language, so it can make predictions on new, unseen posts.\n",
    "\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "\n",
    "## 9. Model Evaluation\n",
    "\n",
    "Test the model on posts it has never seen before and measure how often it gets the answer right. Evaluate with classification metrics and confusion matrix.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=[\"neutral\", \"high-risk\"]))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "```\n",
    "\n",
    "\n",
    "## 10. Model Saving\n",
    "\n",
    "Save the trained model and vectorize (the way text was converted to numbers).\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "\n",
    "joblib.dump(clf, \"suicide_risk_logreg_model.pkl\")\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "```\n",
    "\n",
    "\n",
    "## 11. Inference Function\n",
    "\n",
    "Predict risk for new text.\n",
    "\n",
    "```python\n",
    "def predict_post_risk(title, post_text):\n",
    "    import joblib\n",
    "    clf = joblib.load(\"suicide_risk_logreg_model.pkl\")\n",
    "    vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
    "    text = clean_text(f\"{title} {post_text}\")\n",
    "    X_new = vectorizer.transform([text])\n",
    "    prediction = clf.predict(X_new)\n",
    "    return \"high-risk\" if prediction[0] == 1 else \"neutral\"\n",
    "```\n",
    "\n",
    "\n",
    "## 12. Flask Web Demo\n",
    "\n",
    "**File:** `app.py`\n",
    "\n",
    "- Accepts Reddit post URLs via web form.\n",
    "- Fetches post content using PRAW.\n",
    "- Cleans and classifies the post.\n",
    "- Displays result with risk color coding.\n",
    "\n",
    "**Key Flask route logic:**\n",
    "\n",
    "```python\n",
    "from flask import Flask, request, render_template\n",
    "import praw\n",
    "import joblib\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"YOUR_CLIENT_ID\",\n",
    "    client_secret=\"YOUR_CLIENT_SECRET\",\n",
    "    user_agent=\"YOUR_USER_AGENT\"\n",
    ")\n",
    "\n",
    "app = Flask(__name__)\n",
    "clf = joblib.load(\"suicide_risk_logreg_model.pkl\")\n",
    "vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
    "\n",
    "def extract_post_from_url(url):\n",
    "    submission = reddit.submission(url=url)\n",
    "    return submission.title, submission.selftext\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "def predict():\n",
    "    if request.method == \"POST\":\n",
    "        url = request.form.get(\"url\", \"\")\n",
    "        title, post_text = extract_post_from_url(url)\n",
    "        text = clean_text(f\"{title} {post_text}\")\n",
    "        X_new = vectorizer.transform([text])\n",
    "        prediction = clf.predict(X_new)[0]\n",
    "        label = \"high-risk\" if prediction == 1 else \"neutral\"\n",
    "        return render_template(\"result.html\", label=label)\n",
    "    return render_template(\"form.html\")\n",
    "```\n",
    "\n",
    "\n",
    "## 13. How to Use the Demo\n",
    "\n",
    "1. Run the Flask app:\n",
    "\n",
    "```\n",
    "python app.py\n",
    "```\n",
    "\n",
    "2. Open browser at `http://127.0.0.1:5000/`\n",
    "3. Paste a Reddit post URL into the form.\n",
    "4. View the risk prediction and color-coded result.\n",
    "\n",
    "## 14. File Structure\n",
    "\n",
    "| File/Folder | Purpose |\n",
    "| :-- | :-- |\n",
    "| reddit_posts_preprocessed.csv | Preprocessed dataset |\n",
    "| suicide_risk_logreg_model.pkl | Trained logistic regression model |\n",
    "| tfidf_vectorizer.pkl | Fitted TF-IDF vectorizer |\n",
    "| app.py | Flask web application |\n",
    "| templates/ | HTML templates for Flask |\n",
    "| static/style.css | CSS for web interface |\n",
    "\n",
    "## 15. Notes\n",
    "\n",
    "- Model performance is limited by data quality and representativeness.\n",
    "- For production, secure API credentials and sanitize user input.\n",
    "- The classifier uses only text features; no user metadata is processed.\n",
    "\n",
    "This notebook documents the entire pipeline from data collection to live risk prediction.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Biopython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 179.238479,
   "end_time": "2021-06-28T12:50:34.309644",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-28T12:47:35.071165",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
